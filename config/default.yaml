model_params:
  model_id: "Qwen/Qwen3-4B-Instruct-2507"
  use_4bit: true
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_compute_dtype: "bfloat16" 

device: 'cuda:0'

data_params:
  dataset_path: "data/training_data_tasks_1_2.jsonl" 

lora_params:
  r: 16
  lora_alpha: 32
  target_modules: "all-linear" 
  lora_dropout: 0.05
  bias: "none"
  task_type: "CAUSAL_LM"

training_params:
  output_dir: "./results/Qwen/Qwen3-4B-Instruct-2507-othello-sft"
  max_length: 2048
  batch_size: 4
  # resume_from_checkpoint: "./trainer_output/checkpoint-3000"